# -*- coding: utf-8 -*-
"""PIA IA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mmcZTbDPCAsVUduKpsBOQDhKf1-as-H8

# **PIA IA**

## *Chest CT-Scan images Dataset*


#### Fernanda Hassel Martinez Aragon 1898637
#### Sebastian Valdes Ibarra         1896098
#### Demetrio Manuel Roa Perdomo     2077323

##**Import Libraries**
"""

#Libraries
import numpy as np
import pandas as pd
import os
import PIL
import cv2
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
import shutil
from sklearn.metrics import confusion_matrix, classification_report

#Kraggle Library
!pip install kaggle

"""## **Import Data**"""

from google.colab import files
files.upload()

!mkdir ~/.kaggle
!cp archive.zip ~/.kaggle/
!chmod 600 ~/.kaggle/archive.zip

!kaggle datasets download -d mohamedhanyyy/chest-ctscan-images

!unzip /content/archive.zip

"""## **Preprocessing**"""

# Ruta de la carpeta principal de datos
data_folder = '/content/Data'

# Etiquetas correspondientes a las carpetas
labels = ['adeno', 'large', 'normal', 'squa']

# Arreglo para almacenar las imágenes
images = []
# Arreglo para almacenar las etiquetas
image_labels = []

# Recorremos las subcarpetas (train, test)
for folder in ['test','train','valid']:
    # Recorremos las últimas carpetas (adeno, large, normal, squa)
    for label in labels:
        # Ruta de la carpeta actual
        folder_path = os.path.join(data_folder, folder, label)
        # Obtenemos la lista de archivos en la carpeta actual
        file_list = os.listdir(folder_path)

        # Recorremos los archivos de imagen en la carpeta actual
        for file_name in file_list:
            # Ruta completa de la imagen
            image_path = os.path.join(folder_path, file_name)
            # Cargamos la imagen utilizando OpenCV
            image = cv2.imread(image_path)

            # Si la imagen se cargó correctamente, la añadimos al arreglo images
            if image is not None:
                images.append(image)
                image_labels.append(label)

# Convertimos los arreglos en arrays de NumPy para mayor eficiencia
images = np.array(images)
image_labels = np.array(image_labels)

# Definir rutas de entrenamiento, validación y prueba
train_path = '/content/Data/train'
test_path = '/content/Data/test'
val_path = '/content/Data/valid'

# Función para obtener el número de imágenes en cada conjunto de datos
def GetDatasetSize(path):
    num_of_image = {}
    for folder in os.listdir(path):
        # Contar el número de archivos en la carpeta
        num_of_image[folder] = len(os.listdir(os.path.join(path, folder)));
    return num_of_image;

train_set = GetDatasetSize(train_path)
val_set = GetDatasetSize(val_path)
test_set = GetDatasetSize(test_path)
print('Train set:', train_set)
print('Validation set:', val_set)
print('Test set:', test_set)

from keras.preprocessing.image import ImageDataGenerator

# Crear objeto para los datos de entrenamiento
train_data_augmentation = ImageDataGenerator(
    rescale=1.0/255.0,
    horizontal_flip=True,
    fill_mode='nearest',
    zoom_range=0.2,
    shear_range=0.2,
    width_shift_range=0.2,
    height_shift_range=0.2,
    rotation_range=0.4
)

train_data = train_data_augmentation.flow_from_directory(
    train_path,
    batch_size=5,
    target_size=(256, 256),
    class_mode='categorical'
)

# Crear objeto para los datos de test
test_data_augmentation = ImageDataGenerator(
    rescale=1.0/255.0
)

test_data = test_data_augmentation.flow_from_directory(
    test_path,
    batch_size=5,
    target_size=(256, 256),
    class_mode='categorical'
)

# Imprimir las clases encontradas en cada conjunto de datos
print("Clases encontradas en el conjunto de entrenamiento:", train_data.class_indices)
print("Clases encontradas en el conjunto de test:", test_data.class_indices)

# Saving class names
class_names = ['checkpoint','adeno', 'large', 'normal','squa', ]

# Ruta de la carpeta principal de datos
data_folder = '/content/Data'

# Definir rutas de entrenamiento, validación y prueba
train_path = '/content/Data/train'
val_path = '/content/Data/valid'
test_path = '/content/Data/test'


# Aumentar el tamaño del conjunto de datos con técnicas de aumento de datos
train_data_augmentation = ImageDataGenerator(
    rescale=1.0 / 255.0,
    horizontal_flip=True,
    fill_mode='nearest',
    zoom_range=0.2,
    shear_range=0.2,
    width_shift_range=0.2,
    height_shift_range=0.2,
    rotation_range=0.4
)

val_data_augmentation = ImageDataGenerator(rescale=1.0 / 255.0)

test_data_augmentation = ImageDataGenerator(rescale=1.0 / 255.0)

train_data = train_data_augmentation.flow_from_directory(
    train_path,
    batch_size=32,  # Aumentar el tamaño del lote
    target_size=(256, 256),
    class_mode='categorical'
)

val_data = val_data_augmentation.flow_from_directory(
    val_path,
    batch_size=32,  # Aumentar el tamaño del lote
    target_size=(256, 256),
    class_mode='categorical'
)

test_data = test_data_augmentation.flow_from_directory(
    test_path,
    batch_size=32,  # Aumentar el tamaño del lote
    target_size=(256, 256),
    class_mode='categorical'
)

"""## **Modeling**"""

# Definir el número de clases en tu conjunto de datos
num_classes = 5
# Utilizar una arquitectura diferente como VGG16
pretrained_model = tf.keras.applications.VGG16(
    include_top=False,
    weights='imagenet',
    input_shape=(256, 256, 3)
)

# Establecer las capas del modelo pre-entrenado como no entrenables
for layer in pretrained_model.layers:
    layer.trainable = False

# Crear el modelo secuencial
model = keras.models.Sequential()

# Agregar el modelo pre-entrenado
model.add(pretrained_model)

# Sección de clasificación
from keras.layers import Dense, Flatten, Dropout
model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.5))  # Aumentar la tasa de Dropout para combatir el sobreajuste
model.add(Dense(len(class_names), activation='softmax'))

model.summary()

# Utilizar el optimizador Adam con una tasa de aprendizaje más alta
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Agregar el callback ModelCheckpoint
from tensorflow.keras.callbacks import ModelCheckpoint
checkpoint = ModelCheckpoint(
    filepath='/content/best_model_CNN.hdf5',
    monitor='val_accuracy',
    verbose=1,
    save_best_only=True,
    mode='max'
)

# Agregar el callback EarlyStopping
from tensorflow.keras.callbacks import EarlyStopping
early_stopping = EarlyStopping(
    monitor='val_accuracy',
    min_delta=0.01,
    patience=11,
    verbose=1,
    mode='max',
    restore_best_weights=False
)

"""## **Training**"""

history = model.fit(
    train_data,
    steps_per_epoch=train_data.samples // train_data.batch_size,
    epochs=20,
    validation_data=val_data,
    validation_steps=val_data.samples // val_data.batch_size,
    callbacks=[checkpoint, early_stopping]
)

"""## **Results**"""

model.save('/content/CNN_model.h5')

# Cargar el modelo guardado
from keras.models import load_model
model = load_model('/content/CNN_model.h5')

# Evaluación del modelo
test_loss, test_acc = model.evaluate(test_data)

print('Test accuracy:', test_acc)
print('Test loss:', test_loss)

# Graficar la precisión de entrenamiento vs. precisión de validación durante el entrenamiento
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.title('Training vs validation accuracy')

# Graficar la pérdida de entrenamiento vs. pérdida de validación durante el entrenamiento
plt.plot(history.history['loss'], label='# Graficar la pérdida de entrenamiento vs. pérdida de validación durante el entrenamiento')
plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.title('Training vs validation loss')

# Cargar el modelo en el mejor punto de control
model_best = load_model('/content/best_model_CNN.hdf5')
test_loss, test_acc = model_best.evaluate(test_data)

plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.title('Training vs validation loss')

# Cargar el modelo en el mejor punto de control
model_best = load_model('/content/best_model_CNN.hdf5')
test_loss, test_acc = model_best.evaluate(test_data)

"""## **Predictions**"""

model = load_model('/content/CNN_model.h5')

def prediction_fn(path, _model, classes_dir):
    # Cargar imagen
    img = image.load_img(path, target_size=(256,256))
    # Normalizar imagen
    norm_img = image.img_to_array(img) / 255.0
    # Convertir imagen a matriz numpy
    input_arr_img = np.array([norm_img])
    # Obtener predicciones
    pred = np.argmax(_model.predict(input_arr_img))
    # Devolver nombre de clase
    return classes_dir[pred]

np.random.seed(3)

# Definir las clases disponibles
class_names = ['adeno', 'large', 'normal', 'squa']

# Vectores aleatorios que contienen rutas de imágenes para cada clase
largecell_vector = []
for i in range(2):
    path_largecell = '/content/Data/test/large'
    random_im = np.random.choice(os.listdir(path_largecell))
    largecell_vector.append(path_largecell + '/' + random_im)

adeno_vector = []
for i in range(3):
    path_adeno = '/content/Data/test/adeno'
    random_im = np.random.choice(os.listdir(path_adeno))
    adeno_vector.append(path_adeno + '/' + random_im)

normal_vector = []
for i in range(2):
    path_normal = '/content/Data/test/normal'
    random_im = np.random.choice(os.listdir(path_normal))
    normal_vector.append(path_normal + '/' + random_im)

sq_vector = []
for i in range(3):
    path_sq = '/content/Data/test/squa'
    random_im = np.random.choice(os.listdir(path_sq))
    sq_vector.append(path_sq + '/' + random_im)

# Imprimir las 10 predicciones
from keras.preprocessing import image

for i in largecell_vector:
    true = prediction_fn(i, model, class_names)
    print("Predicción de", i, "\nLa CNN predice", true, "\nY en realidad es large.cell.carcinoma\n")
    test_im = cv2.imread(i, cv2.IMREAD_GRAYSCALE)
    plt.imshow(test_im, cmap='gray')
    plt.title("Predicción de " + i)
    plt.show()

for i in sq_vector:
    true = prediction_fn(i, model, class_names)
    print("Predicción de", i, "\nLa CNN predice", true, "\nY en realidad es squamous.cell.carcinoma\n")

for i in adeno_vector:
    true = prediction_fn(i, model, class_names)
    print("Predicción de", i, "\nLa CNN predice", true, "\nY en realidad es adenocarcinoma\n")

for i in normal_vector:
    true = prediction_fn(i, model, class_names)
    print("Predicción de", i, "\nLa CNN predice", true, "\nY en realidad es normal\n")